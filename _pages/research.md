---
layout: default
permalink: /research/
title: Research
asset:
  image: AI Healthcare.png
---

# Research

<hr class="thin-hr-line">

My research is centered around advancing **machine learning**, **intelligent sensing**, and **biomedical AI**, with the goal of exploring both foundational developments and transformative applications. I am particularly interested in how these technologies can be applied to solve some of the most pressing challenges in healthcare, human-computer interaction, and beyond.

<br>

### **<u>Biomedical AI</u>**

<img title="AI Healthcare" alt="AI Healthcare" src="/assets/images/AI healthcare.png" width="25%">

Healthcare presents one of the most impactful applications of deep learning, and my research in **Biomedical AI** aims to push the boundaries of what's possible in **`medical diagnostics`** and **`treatment planning`**. I am focused on developing models that can analyze medical images and signals, providing non-invasive solutions for `early diagnosis` and `personalized care`.

For example, I’ve worked on deep learning models to reconstruct fetal ECG signals from non-invasive abdominal recordings and to segment vertebrae and discs from lumbar MR images. In the future, I want to explore how **self-supervised learning** and **domain adaptation** can be used to further enhance the accuracy and generalizability of medical AI systems across diverse populations. I’m also deeply interested in exploring how **`multimodal learning`**—integrating image, signal, and clinical data—can create more holistic and precise medical models.

<br>

### **<u>Multimodal Sensing</u>**

<img title="Sensing" alt="Sensing" src="/assets/images/Sensing.png" width="20%">

Beyond visual data, I believe the future of intelligent systems lies in **multimodal sensing**, where diverse data sources such as `Wi-Fi signals`, `IMU sensors`, and `acoustic data` are combined to create richer and more accurate models of human behavior and activity. My past work on **Wi-Fi-based human activity recognition** and **packaging activity recognition** explored how ambient signals can be used to recognize human activities without relying on wearable sensors.

In the future, I want to extend this work to **`sensor fusion`**, developing models that can seamlessly integrate data from various sources, such as cameras, microphones, and environmental sensors, to provide a more comprehensive understanding of context. This has significant applications in areas like **`smart environments`**, **`health monitoring`**, and **`assistive technologies`**, where understanding human behavior is key to improving quality of life.

<br>

### **<u>Computer Vision</u>**

<img title="Vision" alt="Vision" src="/assets/images/Vision.png" width="20%">

Computer vision has the power to transform how machines perceive and interpret the world, and my research focuses on developing more adaptable and **`intelligent vision`** and **`vision-language systems`** systems. I’m particularly drawn to the challenge of making vision models more `robust, scalable, and capable` of working across varying environments.

From **`object detection`** to **`complex scene understanding`**, I see immense potential in areas like `autonomous systems` and `remote sensing`. In the near future, I aim to explore how we can leverage **`neural radiance fields (NeRFs)`** and **`transformer-based architectures`** to achieve breakthroughs in high-fidelity visual reconstruction and real-time object tracking.

<br>




### **<u>Future Research Directions</u>**

My vision for the future is to continue developing AI technologies that can operate in complex, real-world environments. Some key questions I aim to address include:

- How can we make deep learning models more `explainable` and `transparent`, particularly in high-stakes domains like `healthcare`?
- What are the implications of AI in decision-making, and how can we build systems that are both `efficient` and `ethically responsible`?
- How can we expand multimodal learning to integrate even more diverse sources of information, leading to richer and more `context-aware intelligent systems`?

<!-- Through this research, I aim to push the boundaries of AI in ways that are both innovative and grounded in real-world impact. -->
